#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç«¶åˆåˆ†ææ©Ÿèƒ½ä»˜ãé«˜åº¦LPãƒ©ãƒ•æ¡ˆç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ 
"""

import os
import sys
from datetime import datetime
from typing import Dict, Any
from correct_lp_generator import CorrectLPGenerator
from competitor_analyzer import CompetitorAnalyzer
from docbase_lp_uploader import DocbaseLPUploader

class AdvancedLPGenerator(CorrectLPGenerator):
    def __init__(self):
        """åˆæœŸåŒ–"""
        super().__init__()
        self.competitor_analyzer = CompetitorAnalyzer()
    
    def generate_with_competitor_analysis(self, csv_path: str, enable_analysis: bool = True, 
                                        upload_to_docbase: bool = False) -> Dict[str, Any]:
        """ç«¶åˆåˆ†ææ©Ÿèƒ½ä»˜ãLPãƒ©ãƒ•æ¡ˆç”Ÿæˆ"""
        
        print(f"\nğŸš€ é«˜åº¦LPç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ é–‹å§‹")
        print(f"ğŸ“ å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {csv_path}")
        print(f"ğŸ” ç«¶åˆåˆ†æ: {'æœ‰åŠ¹' if enable_analysis else 'ç„¡åŠ¹'}")
        
        try:
            # åŸºæœ¬ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
            product_data = self.parse_kishima_csv(csv_path)
            product_name = product_data.get('å•†å“å', 'å•†å“åä¸æ˜')
            print(f"âœ… å•†å“ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºå®Œäº†: {product_name}")
            
            result = {
                'product_data': product_data,
                'product_name': product_name,
                'analysis_enabled': enable_analysis
            }
            
            # ç«¶åˆåˆ†æå®Ÿè¡Œ
            if enable_analysis:
                print(f"\nğŸ” ç«¶åˆåˆ†æé–‹å§‹...")
                
                # å•†å“ã‚«ãƒ†ã‚´ãƒªè‡ªå‹•åˆ¤å®š
                category = self._detect_category(product_name)
                print(f"ğŸ“Š å•†å“ã‚«ãƒ†ã‚´ãƒª: {category}")
                
                # ç«¶åˆåˆ†æå®Ÿè¡Œ
                competitor_analysis = self.competitor_analyzer.analyze_similar_products(
                    product_name, category
                )
                
                # ç«¶åˆåˆ†æçµæœã‚’çµ±åˆ
                result['competitor_analysis'] = competitor_analysis
                result['category'] = category
                
                print(f"âœ… ç«¶åˆåˆ†æå®Œäº†: {competitor_analysis.get('competitor_count', 0)}å•†å“ã‚’åˆ†æ")
                
                # å¼·åŒ–ç‰ˆLPãƒ©ãƒ•æ¡ˆç”Ÿæˆ
                print(f"\nğŸ“ ç«¶åˆåˆ†æåæ˜ LPãƒ©ãƒ•æ¡ˆç”Ÿæˆä¸­...")
                enhanced_lp_content = self.competitor_analyzer.generate_enhanced_lp_with_analysis(
                    product_data, competitor_analysis
                )
                result['lp_content'] = enhanced_lp_content
                result['generation_type'] = 'ç«¶åˆåˆ†æå¼·åŒ–ç‰ˆ'
                
            else:
                # é€šå¸¸ç‰ˆLPãƒ©ãƒ•æ¡ˆç”Ÿæˆ
                print(f"\nğŸ“ é€šå¸¸LPãƒ©ãƒ•æ¡ˆç”Ÿæˆä¸­...")
                lp_content = self.generate_correct_lp_rough(product_data)
                result['lp_content'] = lp_content
                result['generation_type'] = 'é€šå¸¸ç‰ˆ'
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            safe_product_name = product_name.replace(' ', '_').replace('/', '_')
            
            # LPãƒ©ãƒ•æ¡ˆä¿å­˜
            lp_filename = f"lp_rough_{'enhanced' if enable_analysis else 'standard'}_{safe_product_name}_{timestamp}.md"
            lp_output_path = os.path.join('output', lp_filename)
            
            os.makedirs('output', exist_ok=True)
            with open(lp_output_path, 'w', encoding='utf-8') as f:
                f.write(result['lp_content'])
            
            result['lp_output_path'] = lp_output_path
            print(f"ğŸ“ LPãƒ©ãƒ•æ¡ˆä¿å­˜: {lp_output_path}")
            
            # ç«¶åˆåˆ†æãƒ‡ãƒ¼ã‚¿ä¿å­˜
            if enable_analysis and 'competitor_analysis' in result:
                analysis_filename = f"competitor_analysis_{safe_product_name}_{timestamp}.json"
                analysis_output_path = os.path.join('output', analysis_filename)
                
                import json
                with open(analysis_output_path, 'w', encoding='utf-8') as f:
                    json.dump(result['competitor_analysis'], f, ensure_ascii=False, indent=2)
                
                result['analysis_output_path'] = analysis_output_path
                print(f"ğŸ“Š ç«¶åˆåˆ†æãƒ‡ãƒ¼ã‚¿ä¿å­˜: {analysis_output_path}")
            
            # Docbaseã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            if upload_to_docbase:
                try:
                    print(f"\nğŸ“¤ Docbaseã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­...")
                    
                    # ã‚¿ã‚¤ãƒˆãƒ«ã¨ã‚¿ã‚°è¨­å®š
                    title_prefix = "ã€LPãƒ©ãƒ•æ¡ˆãƒ»ç«¶åˆåˆ†æç‰ˆã€‘" if enable_analysis else "ã€LPãƒ©ãƒ•æ¡ˆã€‘"
                    title = f"{title_prefix}{product_name}"
                    
                    tags = ['LPãƒ©ãƒ•æ¡ˆ']
                    if enable_analysis:
                        tags.extend(['ç«¶åˆåˆ†æ', 'å¸‚å ´èª¿æŸ»', 'æœ€é©åŒ–'])
                        if 'category' in result:
                            tags.append(result['category'])
                    
                    if 'PowerArQ' in product_name:
                        tags.extend(['PowerArQ', 'é›»æ°—æ¯›å¸ƒ', 'ã‚¢ã‚¦ãƒˆãƒ‰ã‚¢'])
                    
                    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ
                    docbase_result = self.docbase_uploader.create_lp_post(
                        title, result['lp_content'], tags
                    )
                    
                    result['docbase_url'] = docbase_result['url']
                    result['docbase_id'] = docbase_result['id']
                    
                    print(f"âœ… Docbaseã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†")
                    print(f"ğŸ“ URL: {docbase_result['url']}")
                    
                except Exception as e:
                    print(f"âŒ Docbaseã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
            
            return result
            
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _detect_category(self, product_name: str) -> str:
        """å•†å“ã‚«ãƒ†ã‚´ãƒªã®è‡ªå‹•åˆ¤å®š"""
        
        product_lower = product_name.lower()
        
        # ã‚¢ã‚¦ãƒˆãƒ‰ã‚¢ãƒ»ã‚­ãƒ£ãƒ³ãƒ—ç³»
        if any(word in product_lower for word in 
               ['powerarq', 'camp', 'outdoor', 'portable', 'ã‚¢ã‚¦ãƒˆãƒ‰ã‚¢', 'ã‚­ãƒ£ãƒ³ãƒ—']):
            return 'outdoor'
        
        # é›»å­æ©Ÿå™¨ãƒ»å®¶é›»ç³»
        elif any(word in product_lower for word in 
                 ['electric', 'electronic', 'blanket', 'é›»æ°—', 'é›»å­', 'æ¯›å¸ƒ', 'ãƒ–ãƒ©ãƒ³ã‚±ãƒƒãƒˆ']):
            return 'electronics'
        
        # ãƒ©ã‚¤ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«ãƒ»ã‚¤ãƒ³ãƒ†ãƒªã‚¢ç³»
        elif any(word in product_lower for word in 
                 ['lifestyle', 'interior', 'home', 'living', 'ãƒ©ã‚¤ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«', 'ã‚¤ãƒ³ãƒ†ãƒªã‚¢']):
            return 'lifestyle'
        
        else:
            return 'electronics'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    
    def generate_comparison_report(self, analysis_result: Dict) -> str:
        """ç«¶åˆæ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        
        if not analysis_result.get('competitor_analysis'):
            return "ç«¶åˆåˆ†æãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“"
        
        competitor_analysis = analysis_result['competitor_analysis']
        product_name = analysis_result.get('product_name', 'å•†å“åä¸æ˜')
        
        report = f"""# ç«¶åˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆ

## ğŸ“Š åˆ†æå¯¾è±¡å•†å“
**{product_name}**

## ğŸ” å¸‚å ´åˆ†æã‚µãƒãƒªãƒ¼
- **åˆ†æå•†å“æ•°**: {competitor_analysis.get('competitor_count', 0)}å•†å“
- **åˆ†ææ—¥æ™‚**: {competitor_analysis.get('analysis_date', 'ä¸æ˜')}
- **å•†å“ã‚«ãƒ†ã‚´ãƒª**: {analysis_result.get('category', 'ä¸æ˜')}

## ğŸ’° ä¾¡æ ¼åˆ†æ
"""
        
        best_practices = competitor_analysis.get('best_practices', {})
        price_range = best_practices.get('price_range', {})
        
        if price_range:
            report += f"""- **å¸‚å ´ä¾¡æ ¼å¸¯**: {price_range.get('min', 0):,}å†† ã€œ {price_range.get('max', 0):,}å††
- **å¹³å‡ä¾¡æ ¼**: {price_range.get('avg', 0):,}å††
- **ä¾¡æ ¼ãƒã‚¸ã‚·ãƒ§ãƒ³**: è‡ªç¤¾å•†å“ã®ä½ç½®ã¥ã‘åˆ†æãŒå¿…è¦
"""
        
        # ãƒˆãƒƒãƒ—è¨´æ±‚ãƒã‚¤ãƒ³ãƒˆ
        report += f"""
## ğŸ¯ å¸‚å ´ã§æˆåŠŸã—ã¦ã„ã‚‹è¨´æ±‚ãƒã‚¤ãƒ³ãƒˆ
"""
        top_appeals = best_practices.get('top_appeals', [])
        for i, (appeal, count) in enumerate(top_appeals, 1):
            report += f"{i}. **{appeal}** (ç«¶åˆ{count}ç¤¾ã§ä½¿ç”¨)\n"
        
        # åŠ¹æœçš„ãªãƒšãƒ¼ã‚¸æ§‹æˆ
        report += f"""
## ğŸ“„ åŠ¹æœçš„ãªãƒšãƒ¼ã‚¸æ§‹æˆ
"""
        effective_structures = best_practices.get('effective_structures', [])
        for i, (structure, count) in enumerate(effective_structures, 1):
            report += f"{i}. **{structure}** (ç«¶åˆ{count}ç¤¾ã§æ¡ç”¨)\n"
        
        # æœ€é©åŒ–ææ¡ˆ
        optimized_appeals = competitor_analysis.get('optimized_appeals', [])
        if optimized_appeals:
            report += f"""
## âœ¨ æœ€é©åŒ–ã•ã‚ŒãŸè¨´æ±‚ãƒã‚¤ãƒ³ãƒˆï¼ˆææ¡ˆï¼‰
"""
            for i, appeal in enumerate(optimized_appeals, 1):
                report += f"{i}. {appeal}\n"
        
        # æ”¹å–„ææ¡ˆ
        recommendations = competitor_analysis.get('recommendations', {})
        if recommendations:
            report += f"""
## ğŸ”§ æ”¹å–„ææ¡ˆ

### ãƒšãƒ¼ã‚¸æ§‹æˆã®æ”¹å–„
"""
            for rec in recommendations.get('page_structure', []):
                report += f"- {rec}\n"
            
            report += f"""
### ã‚³ãƒ”ãƒ¼æ”¹å–„
"""
            for rec in recommendations.get('copy_improvements', []):
                report += f"- {rec}\n"
            
            report += f"""
### æ©Ÿèƒ½å¼·èª¿ãƒã‚¤ãƒ³ãƒˆ
"""
            for feature in recommendations.get('feature_emphasis', []):
                report += f"- {feature}\n"
        
        report += f"""
## ğŸ“ˆ æœŸå¾…ã•ã‚Œã‚‹åŠ¹æœ
- **å·®åˆ¥åŒ–ã®æ˜ç¢ºåŒ–**: ç«¶åˆå•†å“ã¨ã®é•ã„ã‚’é®®æ˜ã«
- **è¨´æ±‚åŠ›å‘ä¸Š**: å¸‚å ´ã§å®Ÿè¨¼æ¸ˆã¿ã®æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³æ´»ç”¨
- **ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ”¹å–„**: åŠ¹æœçš„ãªãƒšãƒ¼ã‚¸æ§‹æˆã®æ¡ç”¨

## ğŸ¯ æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
1. ææ¡ˆã•ã‚ŒãŸè¨´æ±‚ãƒã‚¤ãƒ³ãƒˆã®æ¡ç”¨æ¤œè¨
2. ãƒšãƒ¼ã‚¸æ§‹æˆã®æœ€é©åŒ–å®Ÿè¡Œ
3. ç«¶åˆã¨ã®å·®åˆ¥åŒ–ãƒã‚¤ãƒ³ãƒˆå¼·åŒ–
4. ä¾¡æ ¼æˆ¦ç•¥ã®è¦‹ç›´ã—æ¤œè¨
"""
        
        return report

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    
    if len(sys.argv) < 2:
        print("ğŸš€ é«˜åº¦LPãƒ©ãƒ•æ¡ˆç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ï¼ˆç«¶åˆåˆ†ææ©Ÿèƒ½ä»˜ãï¼‰")
        print("\nä½¿ç”¨æ–¹æ³•:")
        print("  python advanced_lp_generator.py <è¦å®šæ›¸CSVãƒ•ã‚¡ã‚¤ãƒ«> [ã‚ªãƒ—ã‚·ãƒ§ãƒ³]")
        print("\nã‚ªãƒ—ã‚·ãƒ§ãƒ³:")
        print("  --upload          Docbaseã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
        print("  --no-analysis     ç«¶åˆåˆ†æã‚’ç„¡åŠ¹åŒ–")
        print("  --report          ç«¶åˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚‚ç”Ÿæˆ")
        print("\nä¾‹:")
        print("  python advanced_lp_generator.py è¦å®šæ›¸.csv")
        print("  python advanced_lp_generator.py è¦å®šæ›¸.csv --upload")
        print("  python advanced_lp_generator.py è¦å®šæ›¸.csv --upload --report")
        print("  python advanced_lp_generator.py è¦å®šæ›¸.csv --no-analysis")
        sys.exit(1)
    
    csv_path = sys.argv[1]
    upload_flag = '--upload' in sys.argv
    no_analysis_flag = '--no-analysis' in sys.argv
    report_flag = '--report' in sys.argv
    
    enable_analysis = not no_analysis_flag
    
    if not os.path.exists(csv_path):
        print(f"âŒ è¦å®šæ›¸CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_path}")
        sys.exit(1)
    
    try:
        # é«˜åº¦LPç”Ÿæˆå®Ÿè¡Œ
        generator = AdvancedLPGenerator()
        result = generator.generate_with_competitor_analysis(
            csv_path, 
            enable_analysis=enable_analysis, 
            upload_to_docbase=upload_flag
        )
        
        if not result:
            print("âŒ ç”Ÿæˆå‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ")
            sys.exit(1)
        
        # ç«¶åˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        if report_flag and enable_analysis:
            try:
                print(f"\nğŸ“Š ç«¶åˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...")
                
                report_content = generator.generate_comparison_report(result)
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                product_name = result.get('product_name', 'å•†å“å').replace(' ', '_')
                report_path = os.path.join('output', f'competitor_report_{product_name}_{timestamp}.md')
                
                with open(report_path, 'w', encoding='utf-8') as f:
                    f.write(report_content)
                
                print(f"ğŸ“Š ç«¶åˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_path}")
                result['report_path'] = report_path
                
            except Exception as e:
                print(f"âš ï¸ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        
        # çµæœã‚µãƒãƒªãƒ¼è¡¨ç¤º
        print(f"\nğŸ‰ ç”Ÿæˆå®Œäº†ï¼")
        print(f"ğŸ“¦ ç”Ÿæˆã‚¿ã‚¤ãƒ—: {result.get('generation_type', 'ä¸æ˜')}")
        print(f"ğŸ“ LPãƒ©ãƒ•æ¡ˆ: {result.get('lp_output_path')}")
        
        if enable_analysis:
            competitor_count = result.get('competitor_analysis', {}).get('competitor_count', 0)
            print(f"ğŸ” ç«¶åˆåˆ†æ: {competitor_count}å•†å“ã‚’åˆ†æ")
            if 'analysis_output_path' in result:
                print(f"ğŸ“Š åˆ†æãƒ‡ãƒ¼ã‚¿: {result['analysis_output_path']}")
        
        if report_flag and 'report_path' in result:
            print(f"ğŸ“‹ åˆ†æãƒ¬ãƒãƒ¼ãƒˆ: {result['report_path']}")
        
        if 'docbase_url' in result:
            print(f"ğŸŒ Docbase URL: {result['docbase_url']}")
        
        print(f"\nâœ¨ é«˜åº¦LPç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ å®Œäº†")
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()