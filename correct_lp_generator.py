#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ­£ã—ã„ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ã®LPãƒ©ãƒ•æ¡ˆç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ 
"""

import os
import sys
import csv
from datetime import datetime
from typing import Dict, Any, List
from docbase_lp_uploader import DocbaseLPUploader

class CorrectLPGenerator:
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.docbase_uploader = DocbaseLPUploader()
    
    def parse_kishima_csv(self, csv_path: str) -> Dict[str, Any]:
        """åŠ å³¶å•†äº‹è¦å®šæ›¸CSVã‚’æ­£ç¢ºã«è§£æ"""
        
        with open(csv_path, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            rows = list(reader)
        
        # ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
        product_data = {}
        jan_codes = []
        
        for i, row in enumerate(rows):
            if len(row) >= 6 and row[4] and row[5]:
                key = row[4].strip()
                value = row[5].strip()
                product_data[key] = value
                
                # JANã‚³ãƒ¼ãƒ‰è¡Œã®ç‰¹åˆ¥å‡¦ç†
                if "JANã‚³ãƒ¼ãƒ‰" in key:
                    # ã“ã®è¡Œã¨æ¬¡ã®è¡Œã§JANã‚³ãƒ¼ãƒ‰æƒ…å ±ã‚’åé›†
                    jan_codes.append(value)
                    # æ¬¡ã®è¡Œã‚‚ãƒã‚§ãƒƒã‚¯
                    if i + 1 < len(rows) and len(rows[i + 1]) >= 6 and rows[i + 1][5]:
                        next_jan = rows[i + 1][5].strip()
                        if next_jan and ('ï¼š' in next_jan or ':' in next_jan):
                            jan_codes.append(next_jan)
        
        # JANã‚³ãƒ¼ãƒ‰æƒ…å ±ã‚’ã¾ã¨ã‚ã‚‹
        if jan_codes:
            product_data["JANã‚³ãƒ¼ãƒ‰\nï¼ˆãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³åˆ¥ï¼‰"] = "\n".join(jan_codes)
        
        # ã‚»ãƒ¼ãƒ«ã‚¹ãƒã‚¤ãƒ³ãƒˆã®ç‰¹åˆ¥å‡¦ç†
        sales_points = []
        for i, row in enumerate(rows):
            if len(row) > 3 and row[3] and "ã‚»ãƒ¼ãƒ«ã‚¹ãƒã‚¤ãƒ³ãƒˆ" in row[3]:
                # ã‚»ãƒ¼ãƒ«ã‚¹ãƒã‚¤ãƒ³ãƒˆè¡Œä»¥é™ã‚’å–å¾—
                for j in range(i+1, len(rows)):
                    if len(rows[j]) > 3 and rows[j][3]:
                        point_text = rows[j][3].strip()
                        if point_text.startswith("â—"):
                            sales_points.append(point_text.replace("â—", "").strip())
                break
        
        product_data["ã‚»ãƒ¼ãƒ«ã‚¹ãƒã‚¤ãƒ³ãƒˆ"] = sales_points
        
        return product_data
    
    def generate_correct_lp_rough(self, product_data: Dict) -> str:
        """æ­£ã—ã„ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®LPãƒ©ãƒ•æ¡ˆã‚’ç”Ÿæˆ"""
        
        # åŸºæœ¬æƒ…å ±å–å¾—
        product_name = product_data.get('å•†å“å', 'PowerArQ Electric Blanket Lite')
        product_kana = product_data.get('å•†å“åã‚«ãƒŠ', '')
        model_number = product_data.get('ãƒ¡ãƒ¼ã‚«ãƒ¼å‹ç•ª', '')
        jan_info = product_data.get('JANã‚³ãƒ¼ãƒ‰\nï¼ˆãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³åˆ¥ï¼‰', '')
        size = product_data.get('å•†å“ã‚µã‚¤ã‚º(cm)', '')
        weight = product_data.get('1å€‹ é‡é‡(kg)', '')
        power = product_data.get('å®šæ ¼', '')
        material = product_data.get('è¡¨é¢ç´ æ', '')
        release_date = product_data.get('ç™ºå£²æ—¥', '')
        sales_points = product_data.get('ã‚»ãƒ¼ãƒ«ã‚¹ãƒã‚¤ãƒ³ãƒˆ', [])
        
        # JANã‚³ãƒ¼ãƒ‰ã®è§£æï¼ˆè¤‡æ•°è¡Œå¯¾å¿œï¼‰
        jan_colors = []
        if jan_info:
            # ã¾ãšå…¨ä½“ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰è‰²ã¨JANã‚’æŠ½å‡º
            full_text = jan_info.replace('\n', ' ')
            # ãƒ–ãƒ©ãƒƒã‚¯ã¨ãƒ™ãƒ¼ã‚¸ãƒ¥ã®æƒ…å ±ã‚’å€‹åˆ¥ã«å‡¦ç†
            # æ­£è¦è¡¨ç¾çš„ãªå‡¦ç†ã§ã‚ˆã‚Šç¢ºå®Ÿã«æŠ½å‡º
            import re
            color_patterns = [
                (r'ãƒ–ãƒ©ãƒƒã‚¯[ï¼š:]\s*(\d+)', 'ãƒ–ãƒ©ãƒƒã‚¯'),
                (r'ãƒ™ãƒ¼ã‚¸ãƒ¥[ï¼š:]\s*(\d+)', 'ãƒ™ãƒ¼ã‚¸ãƒ¥')
            ]
            
            for pattern, color in color_patterns:
                match = re.search(pattern, full_text)
                if match:
                    jan_colors.append({'color': color, 'jan': match.group(1)})
        
        # LPãƒ©ãƒ•æ¡ˆç”Ÿæˆ
        lp_content = f"""# LPãƒ©ãƒ•
## ä½œæˆã®ç›®çš„ã€æ„å›³
{product_name}ã®è²©å£²ä¿ƒé€²ã¨ãƒ–ãƒ©ãƒ³ãƒ‰èªçŸ¥å‘ä¸Šã®ãŸã‚

## å¯¾è±¡å•†å“
### å•†å“å
{product_name}
{f"ï¼ˆ{product_kana}ï¼‰" if product_kana else ""}

### SKUãƒ»JAN
| ç¨®é¡ | SKU | JAN |
| --- | --- | --- |
"""
        
        # SKUãƒ»JANãƒ†ãƒ¼ãƒ–ãƒ«
        if jan_colors:
            for item in jan_colors:
                sku = f"{model_number}-{item['color']}" if model_number else f"PAQ-{item['color']}"
                lp_content += f"| {item['color']} | {sku} | {item['jan']} |\n"
        else:
            lp_content += "| ã‚«ãƒ©ãƒ¼ãƒ»ã‚µã‚¤ã‚º | SKUã‚³ãƒ¼ãƒ‰ | JANã‚³ãƒ¼ãƒ‰ |\n"
        
        # åŸºæœ¬æƒ…å ±
        lp_content += f"""
## åŸºæœ¬æƒ…å ±
### ãƒãƒŠãƒ¼ã‚¹ãƒšãƒƒã‚¯
| é …ç›® | å†…å®¹ |
| --- | --- |
| ã‚µã‚¤ã‚º | PC:W1200pxã€SPï¼š850pxã€flickï¼š1000px |
| æ‹¡å¼µå­ | JPG |
| ã‚«ãƒ©ãƒ¼ãƒ¢ãƒ¼ãƒ‰ | RGB |
| ç”»è³ª | ãªã‚‹ã¹ãç”»è³ªå„ªå…ˆã§å¤§ä¸ˆå¤«ã§ã™ |
| åœ§ç¸®æ–¹å¼ | ãƒ—ãƒ­ã‚°ãƒ¬ãƒƒã‚·ãƒ–ã¨ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã§å®¹é‡ãŒå°ã•ã„æ–¹ã€åŒã˜å®¹é‡ã®å ´åˆã¯ãƒ—ãƒ­ã‚°ãƒ¬ãƒƒã‚·ãƒ–å„ªå…ˆ |
| è§£åƒåº¦ | 72ppi |
| ã‚¢ãƒ³ãƒã‚¨ã‚¤ãƒªã‚¢ã‚¹ | æ–‡å­—ã«æœ€é© |
| ICCãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ« | æ¶ˆã—ã¦ãã ã•ã„ |

### ãƒ•ã‚©ãƒ³ãƒˆã€ã‚«ãƒ©ãƒ¼æŒ‡å®š

ä¸‹è¨˜ã€ãƒˆãƒ³ãƒãƒŠã‚’è¸ã¾ãˆã¦ä½œæˆãŠé¡˜ã„ã—ã¾ã™ã€‚
ï¼ˆåˆ¥é€”å…±æœ‰ï¼‰

### ãƒ™ãƒ¼ã‚¹ã®ãƒ‡ãƒ¼ã‚¿

ï¼ˆåˆ¥é€”å…±æœ‰ï¼‰

---
# LPæ§‹æˆ
| æšæ•° | ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æ¦‚è¦ |
| --- | --- |
| 1æšç›® | TOPã‚­ãƒ£ãƒƒãƒ |
| 2æšç›® | å£²ã‚Œã¦ã„ã‚‹è¨´æ±‚ãƒ»å®Ÿç¸¾ |
| 3æšç›® | ãƒ–ãƒ©ãƒ³ãƒ‰ä¾¡å€¤ãƒ»å®‰å…¨æ€§ |
| 4æšç›® | ãƒ¡ã‚¤ãƒ³æ©Ÿèƒ½ãƒ»ç‰¹å¾´1ï¼ˆ10æ®µéšæ¸©åº¦èª¿ç¯€ï¼‰ |
| 5æšç›® | ãƒ¡ã‚¤ãƒ³æ©Ÿèƒ½ãƒ»ç‰¹å¾´2ï¼ˆéç†±ä¿è­·ãƒ»å®‰å…¨æ€§ï¼‰ |
| 6æšç›® | ä½¿ç”¨ã‚·ãƒ¼ãƒ³ |
| 7æšç›® | ã‚µã‚¤ã‚ºãƒ»ã‚¹ãƒšãƒƒã‚¯è©³ç´° |
| 8æšç›® | ä»˜å±å“ãƒ»åŒæ¢±ç‰© |
| 9æšç›® | ä¿è¨¼ãƒ»ã‚¢ãƒ•ã‚¿ãƒ¼ã‚µãƒ¼ãƒ“ã‚¹ |
| 10æšç›® | ã‚ˆãã‚ã‚‹è³ªå• |

---
# ãƒ©ãƒ•è©³ç´°

## 1æšç›®

### ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæ¡ˆ
ã€ç”»åƒæº–å‚™ä¸­ã€‘

å•†å“ã®é­…åŠ›ãŒä¸€ç›®ã§ä¼ã‚ã‚‹ãƒ‡ã‚¶ã‚¤ãƒ³ã«ã—ã¦ãã ã•ã„ã€‚

### ãƒ†ã‚­ã‚¹ãƒˆ

{product_name}

{f"ã‚­ãƒ£ãƒ³ãƒ—ã‚®ã‚¢ã«åˆã†ãƒ‡ã‚¶ã‚¤ãƒ³" if sales_points and any("ã‚­ãƒ£ãƒ³ãƒ—" in point for point in sales_points) else "å¿«é©ãªæ¸©ã‚‚ã‚Šã‚’"}

{f"â€¢ 10æ®µéšã®æ¸©åº¦èª¿ç¯€" if sales_points and any("10æ®µéš" in point for point in sales_points) else ""}
{f"â€¢ éç†±ä¿è­·ã‚·ã‚¹ãƒ†ãƒ æ­è¼‰" if sales_points and any("éç†±ä¿è­·" in point for point in sales_points) else ""}
{f"â€¢ ä¸¸æ´—ã„å¯èƒ½" if sales_points and any("ä¸¸æ´—ã„" in point for point in sales_points) else ""}

### ä½¿ç”¨ç”»åƒ

ã€ç”»åƒæº–å‚™ä¸­ã€‘

## 2æšç›®

### ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæ¡ˆ
ã€ç”»åƒæº–å‚™ä¸­ã€‘

æ•°å­—ã‚„ãƒ­ã‚´ã‚’åŠ¹æœçš„ã«é…ç½®ã—ã¦ãã ã•ã„ã€‚

### ãƒ†ã‚­ã‚¹ãƒˆ

PowerARQãƒ–ãƒ©ãƒ³ãƒ‰

ä¿¡é ¼ã®å®Ÿç¸¾
ç´¯è¨ˆè²©å£²å°æ•°â—‹â—‹ä¸‡å°çªç ´
â€»2025å¹´â—‹æœˆæ™‚ç‚¹

## 3æšç›®

### ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæ¡ˆ
ã€ç”»åƒæº–å‚™ä¸­ã€‘

### ãƒ†ã‚­ã‚¹ãƒˆ

PowerARQãƒ–ãƒ©ãƒ³ãƒ‰ã®å®‰å¿ƒå“è³ª

æ—¥æœ¬ãƒ–ãƒ©ãƒ³ãƒ‰ã¨ã—ã¦ã®å“è³ªãƒ»å®‰å…¨æ€§

### ä½¿ç”¨ç”»åƒ

ã€ç”»åƒæº–å‚™ä¸­ã€‘

## 4æšç›®

### ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæ¡ˆ
ã€ç”»åƒæº–å‚™ä¸­ã€‘

### ãƒ†ã‚­ã‚¹ãƒˆ

10æ®µéšã®æ¸©åº¦èª¿ç¯€

ãŠå¥½ã¿ã®æ¸©ã‹ã•ã«ç´°ã‹ãè¨­å®š
{f"ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ã‹ã‚‰ç°¡å˜æ“ä½œ" if sales_points and any("ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼" in point for point in sales_points) else ""}

### ä½¿ç”¨ç”»åƒ

ã€ç”»åƒæº–å‚™ä¸­ã€‘

## 5æšç›®

### ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæ¡ˆ
ã€ç”»åƒæº–å‚™ä¸­ã€‘

### ãƒ†ã‚­ã‚¹ãƒˆ

å®‰å…¨æ©Ÿèƒ½æ­è¼‰

{f"éç†±ä¿è­·ã‚·ã‚¹ãƒ†ãƒ " if sales_points and any("éç†±ä¿è­·" in point for point in sales_points) else "å®‰å…¨æ©Ÿèƒ½"}
å®‰å¿ƒã—ã¦ãŠä½¿ã„ã„ãŸã ã‘ã¾ã™

### ä½¿ç”¨ç”»åƒ

ã€ç”»åƒæº–å‚™ä¸­ã€‘

## 6æšç›®

### ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæ¡ˆ
ã€ç”»åƒæº–å‚™ä¸­ã€‘

### ãƒ†ã‚­ã‚¹ãƒˆ

ã„ã¤ã§ã‚‚ã€ã©ã“ã§ã‚‚æš–ã‹ã

{f"ã‚­ãƒ£ãƒ³ãƒ—ãƒ»ã‚¢ã‚¦ãƒˆãƒ‰ã‚¢ãƒ»è‡ªå®…" if sales_points and any("ã‚­ãƒ£ãƒ³ãƒ—" in point for point in sales_points) else "ãƒªãƒ“ãƒ³ã‚°ãƒ»å¯å®¤ãƒ»æ›¸æ–"}
ã‚ã‚‰ã‚†ã‚‹ã‚·ãƒ¼ãƒ³ã§æ´»èº

### ä½¿ç”¨ç”»åƒ

ã€ç”»åƒæº–å‚™ä¸­ã€‘

## 7æšç›®

### ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæ¡ˆ
ã€ç”»åƒæº–å‚™ä¸­ã€‘

### ãƒ†ã‚­ã‚¹ãƒˆ

ä»•æ§˜ãƒ»ã‚¹ãƒšãƒƒã‚¯

{f"ã‚µã‚¤ã‚ºï¼š{size}" if size else ""}
{f"é‡é‡ï¼š{weight}" if weight else ""}
{f"å®šæ ¼ï¼š{power}" if power else ""}
{f"ç´ æï¼š{material}" if material else ""}

### ä½¿ç”¨ç”»åƒ

ã€ç”»åƒæº–å‚™ä¸­ã€‘

## 8æšç›®

### ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæ¡ˆ
ã€ç”»åƒæº–å‚™ä¸­ã€‘

### ãƒ†ã‚­ã‚¹ãƒˆ

ä»˜å±å“ãƒ»åŒæ¢±ç‰©

ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼
å–æ‰±èª¬æ˜æ›¸
ä¿è¨¼æ›¸

### ä½¿ç”¨ç”»åƒ

ã€ç”»åƒæº–å‚™ä¸­ã€‘

## 9æšç›®

### ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæ¡ˆ
ã€ç”»åƒæº–å‚™ä¸­ã€‘

### ãƒ†ã‚­ã‚¹ãƒˆ

å®‰å¿ƒã®ä¿è¨¼ãƒ»ã‚¢ãƒ•ã‚¿ãƒ¼ã‚µãƒ¼ãƒ“ã‚¹

ãƒ¡ãƒ¼ã‚«ãƒ¼ä¿è¨¼
å……å®Ÿã®ã‚µãƒãƒ¼ãƒˆä½“åˆ¶

## 10æšç›®

### ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæ¡ˆ
ã€ç”»åƒæº–å‚™ä¸­ã€‘

### ãƒ†ã‚­ã‚¹ãƒˆ

ã‚ˆãã‚ã‚‹è³ªå•

Q: é›»æ°—ä»£ã¯ã©ã®ãã‚‰ã„ã‹ã‹ã‚Šã¾ã™ã‹ï¼Ÿ
A: 1æ™‚é–“ã‚ãŸã‚Šç´„â—‹å††ã§ã™ï¼ˆä¸­é–“è¨­å®šæ™‚ï¼‰

{f"Q: ä¸¸æ´—ã„ã§ãã¾ã™ã‹ï¼Ÿ" if sales_points and any("ä¸¸æ´—ã„" in point for point in sales_points) else "Q: ãŠæ‰‹å…¥ã‚Œæ–¹æ³•ã¯ï¼Ÿ"}
{f"A: ã¯ã„ã€ä¸¸æ´—ã„å¯èƒ½ã§ã™" if sales_points and any("ä¸¸æ´—ã„" in point for point in sales_points) else "A: ç°¡å˜ãªãŠæ‰‹å…¥ã‚Œã§æ¸…æ½”ã«ä¿ã¦ã¾ã™"}

"""
        
        return lp_content
    
    def generate_from_kishima_csv(self, csv_path: str, upload_to_docbase: bool = False) -> Dict[str, Any]:
        """åŠ å³¶å•†äº‹è¦å®šæ›¸CSVã‹ã‚‰æ­£ã—ã„LPãƒ©ãƒ•æ¡ˆã‚’ç”Ÿæˆ"""
        
        print(f"\nğŸ“‹ è¦å®šæ›¸è§£æé–‹å§‹: {csv_path}")
        
        try:
            # ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
            product_data = self.parse_kishima_csv(csv_path)
            print(f"âœ… è¦å®šæ›¸è§£æå®Œäº†: {product_data.get('å•†å“å', 'å•†å“åä¸æ˜')}")
            
            # LPãƒ©ãƒ•æ¡ˆç”Ÿæˆ
            lp_content = self.generate_correct_lp_rough(product_data)
            print("âœ… LPãƒ©ãƒ•æ¡ˆç”Ÿæˆå®Œäº†")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            product_name = product_data.get('å•†å“å', 'å•†å“å').replace(' ', '_')
            output_filename = f"lp_rough_correct_{product_name}_{timestamp}.md"
            output_path = os.path.join('output', output_filename)
            
            os.makedirs('output', exist_ok=True)
            
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(lp_content)
            
            print(f"ğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_path}")
            
            result = {
                'lp_content': lp_content,
                'output_path': output_path,
                'product_data': product_data
            }
            
            # Docbaseã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            if upload_to_docbase:
                try:
                    title = f"ã€LPãƒ©ãƒ•æ¡ˆã€‘{product_data.get('å•†å“å', 'å•†å“å')}"
                    tags = ['LPãƒ©ãƒ•æ¡ˆ', 'æ­£å¼ç‰ˆ', 'è¦å®šæ›¸ç”Ÿæˆ']
                    
                    if 'PowerArQ' in product_data.get('å•†å“å', ''):
                        tags.extend(['PowerArQ', 'é›»æ°—æ¯›å¸ƒ'])
                    
                    print(f"\nğŸ“¤ Docbaseã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­...")
                    docbase_result = self.docbase_uploader.create_lp_post(title, lp_content, tags)
                    
                    result['docbase_url'] = docbase_result['url']
                    result['docbase_id'] = docbase_result['id']
                    
                    print(f"âœ… Docbaseã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†")
                    print(f"ğŸ“ URL: {docbase_result['url']}")
                    
                except Exception as e:
                    print(f"âŒ Docbaseã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
            
            return result
            
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            return None

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  python correct_lp_generator.py <è¦å®šæ›¸CSVãƒ•ã‚¡ã‚¤ãƒ«> [--upload]")
        print("\nä¾‹:")
        print("  python correct_lp_generator.py è¦å®šæ›¸.csv")
        print("  python correct_lp_generator.py è¦å®šæ›¸.csv --upload")
        sys.exit(1)
    
    csv_path = sys.argv[1]
    upload_flag = '--upload' in sys.argv
    
    if not os.path.exists(csv_path):
        print(f"âŒ è¦å®šæ›¸CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_path}")
        sys.exit(1)
    
    try:
        generator = CorrectLPGenerator()
        result = generator.generate_from_kishima_csv(csv_path, upload_to_docbase=upload_flag)
        
        if result:
            print(f"\nğŸ‰ å‡¦ç†å®Œäº†ï¼")
            print(f"ğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {result['output_path']}")
            if 'docbase_url' in result:
                print(f"ğŸŒ Docbase URL: {result['docbase_url']}")
        else:
            print("âŒ å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ")
            sys.exit(1)
            
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()