#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŠ å³¶å•†äº‹ã®è¦å®šæ›¸CSVã‹ã‚‰LPãƒ©ãƒ•æ¡ˆã‚’ç›´æ¥ç”Ÿæˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import os
import sys
import csv
import json
from datetime import datetime
from typing import Dict, Any, List
from lp_rough_generator import LPRoughGenerator
from docbase_lp_uploader import DocbaseLPUploader

class KishimaSpecToLPGenerator:
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.lp_generator = LPRoughGenerator()
        
    def parse_kishima_csv(self, csv_path: str) -> Dict[str, Any]:
        """åŠ å³¶å•†äº‹è¦å®šæ›¸CSVã‚’è§£æã—ã¦LPç”¨ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›"""
        
        # CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        with open(csv_path, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            rows = list(reader)
        
        # ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºç”¨ã®è¾æ›¸
        spec_data = {}
        
        for row in rows:
            if len(row) >= 6:
                if row[4]:  # ã‚­ãƒ¼ï¼ˆé …ç›®åï¼‰ãŒã‚ã‚‹å ´åˆ
                    key = row[4].strip()
                    value = row[5].strip() if row[5] else ""
                    
                    if key and value:
                        spec_data[key] = value
                
                # ã‚»ãƒ¼ãƒ«ã‚¹ãƒã‚¤ãƒ³ãƒˆã®ç‰¹åˆ¥å‡¦ç†
                if row[3] and row[3].strip() == "ã‚»ãƒ¼ãƒ«ã‚¹ãƒã‚¤ãƒ³ãƒˆ":
                    sales_points = []
                    for i in range(len(rows)):
                        if i > rows.index(row) and rows[i][3]:
                            point = rows[i][3].strip()
                            if point and point.startswith("â—"):
                                sales_points.append(point.replace("â—", "").strip())
                    spec_data["ã‚»ãƒ¼ãƒ«ã‚¹ãƒã‚¤ãƒ³ãƒˆ"] = "\\n".join(sales_points)
                    break
        
        # LPãƒ©ãƒ•æ¡ˆç”¨ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã«å¤‰æ›
        product_data = {
            'product_name': spec_data.get('å•†å“å', 'PowerArQ Electric Blanket Lite'),
            'product_kana': spec_data.get('å•†å“åã‚«ãƒŠ', ''),
            'model_number': spec_data.get('ãƒ¡ãƒ¼ã‚«ãƒ¼å‹ç•ª', ''),
            'purpose': 'PowerArQ Electric Blanket Liteã®è²©å£²ä¿ƒé€²ã¨ãƒ–ãƒ©ãƒ³ãƒ‰èªçŸ¥å‘ä¸Šã®ãŸã‚',
            'price': 'èª¿æ•´ä¸­ï¼ˆãƒ¡ãƒ¼ã‚«ãƒ¼å¸Œæœ›å°å£²ä¾¡æ ¼ï¼‰',
            'release_date': spec_data.get('ç™ºå£²æ—¥', '2025å¹´9æœˆ30æ—¥'),
            'target_platform': 'ECãƒ»ã‚­ãƒ£ãƒ³ãƒ—ç”¨å“åº—ãƒ»å®¶é›»é‡è²©åº—',
            'target_users': 'ã‚­ãƒ£ãƒ³ãƒ‘ãƒ¼ã€å¯’ãŒã‚Šã®æ–¹ã€é›»æ°—ä»£ã‚’ç¯€ç´„ã—ãŸã„æ–¹ã€ã‚¢ã‚¦ãƒˆãƒ‰ã‚¢æ„›å¥½å®¶',
            'main_appeal': '10æ®µéšæ¸©åº¦è¨­å®šÃ—ã‚¢ã‚¦ãƒˆãƒ‰ã‚¢å¯¾å¿œã§å¿«é©ãªæ¸©ã‚‚ã‚Šã‚’',
            'brand_value': 'PowerARQãƒ–ãƒ©ãƒ³ãƒ‰ã®ä¿¡é ¼æ€§ã¨ã‚¢ã‚¦ãƒˆãƒ‰ã‚¢ç‰¹åŒ–è¨­è¨ˆ',
            'specifications': {
                'ã‚µã‚¤ã‚º': spec_data.get('å•†å“ã‚µã‚¤ã‚º(cm)', 'ç´„188Ã—130cm'),
                'é‡é‡': spec_data.get('1å€‹ é‡é‡(kg)', 'ç´„2.0kg'),
                'å®šæ ¼': spec_data.get('å®šæ ¼', 'äº¤æµ100V / 115W'),
                'è¡¨é¢ç´ æ': spec_data.get('è¡¨é¢ç´ æ', 'ãƒãƒªã‚¨ã‚¹ãƒ†ãƒ«ï¼š100%'),
                'è¡¨é¢æ¸©åº¦': spec_data.get('è¡¨é¢æ¸©åº¦', 'ç´„XXâ„ƒ'),
                'æ¸©åº¦èª¿ç¯€': '10æ®µéš',
                'å®‰å…¨æ©Ÿèƒ½': 'éç†±ä¿è­·ã‚·ã‚¹ãƒ†ãƒ ',
                'ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹': 'ä¸¸æ´—ã„å¯èƒ½'
            },
            'design_variants': self._extract_jan_codes(spec_data.get('JANã‚³ãƒ¼ãƒ‰\nï¼ˆãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³åˆ¥ï¼‰', '')),
            'sku_list': self._create_sku_list(spec_data.get('JANã‚³ãƒ¼ãƒ‰\nï¼ˆãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³åˆ¥ï¼‰', ''), spec_data.get('ãƒ¡ãƒ¼ã‚«ãƒ¼å‹ç•ª', '')),
            'main_features': self._extract_sales_points(spec_data.get('ã‚»ãƒ¼ãƒ«ã‚¹ãƒã‚¤ãƒ³ãƒˆ', '')),
            'lp_structure': [
                'TOPã‚­ãƒ£ãƒƒãƒãƒ»å•†å“ç´¹ä»‹',
                'PowerARQãƒ–ãƒ©ãƒ³ãƒ‰Ã—ã‚¢ã‚¦ãƒˆãƒ‰ã‚¢',
                '10æ®µéšæ¸©åº¦èª¿ç¯€æ©Ÿèƒ½',
                'ã‚¢ã‚¦ãƒˆãƒ‰ã‚¢å¯¾å¿œç´ æãƒ»ãƒ‡ã‚¶ã‚¤ãƒ³',
                'ä½¿ç”¨ã‚·ãƒ¼ãƒ³ãƒ»ã‚­ãƒ£ãƒ³ãƒ—ãƒ©ã‚¤ãƒ•',
                'ã‚µã‚¤ã‚ºãƒ»ã‚¹ãƒšãƒƒã‚¯è©³ç´°',
                'ã‚«ãƒ©ãƒ¼ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³',
                'å®‰å…¨æ©Ÿèƒ½ãƒ»ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹',
                'ã‚ˆãã‚ã‚‹è³ªå•',
                'è³¼å…¥ç‰¹å…¸ãƒ»è²©å£²åº—æƒ…å ±'
            ],
            'page_details': self._create_page_details(spec_data)
        }
        
        return product_data
    
    def _extract_jan_codes(self, jan_text: str) -> List[str]:
        """JANã‚³ãƒ¼ãƒ‰æ–‡å­—åˆ—ã‹ã‚‰ã‚«ãƒ©ãƒ¼ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æŠ½å‡º"""
        if not jan_text:
            return ['ãƒ–ãƒ©ãƒƒã‚¯', 'ãƒ™ãƒ¼ã‚¸ãƒ¥']
        
        colors = []
        lines = jan_text.split('\n') if '\n' in jan_text else [jan_text]
        for line in lines:
            if 'ï¼š' in line:
                color = line.split('ï¼š')[0].strip()
                if color:
                    colors.append(color)
        return colors if colors else ['ãƒ–ãƒ©ãƒƒã‚¯', 'ãƒ™ãƒ¼ã‚¸ãƒ¥']
    
    def _create_sku_list(self, jan_text: str, model_number: str) -> List[Dict]:
        """SKUãƒªã‚¹ãƒˆã‚’ä½œæˆ"""
        sku_list = []
        colors = self._extract_jan_codes(jan_text)
        jan_codes = self._extract_jan_numbers(jan_text)
        
        for i, color in enumerate(colors):
            jan_code = jan_codes[i] if i < len(jan_codes) else '4571427130640'
            sku_code = f"{model_number}-{color[:2].upper()}" if model_number else f"PAQ-BLANKET-{color[:2].upper()}"
            
            sku_list.append({
                'type': color,
                'sku': sku_code,
                'jan': jan_code
            })
        
        return sku_list
    
    def _extract_jan_numbers(self, jan_text: str) -> List[str]:
        """JANã‚³ãƒ¼ãƒ‰ç•ªå·ã‚’æŠ½å‡º"""
        if not jan_text:
            return ['4571427130640', '4571427130657']
        
        jan_numbers = []
        lines = jan_text.split('\n') if '\n' in jan_text else [jan_text]
        for line in lines:
            if 'ï¼š' in line:
                jan = line.split('ï¼š')[1].strip()
                if jan and jan.isdigit():
                    jan_numbers.append(jan)
        return jan_numbers if jan_numbers else ['4571427130640', '4571427130657']
    
    def _extract_sales_points(self, sales_text: str) -> List[str]:
        """ã‚»ãƒ¼ãƒ«ã‚¹ãƒã‚¤ãƒ³ãƒˆã‚’ç‰¹å¾´ãƒªã‚¹ãƒˆã«å¤‰æ›"""
        if not sales_text:
            return [
                '10æ®µéšã®æ¸©åº¦èª¿ç¯€æ©Ÿèƒ½',
                'ã‚¢ã‚¦ãƒˆãƒ‰ã‚¢å‘ã‘ãƒ‡ã‚¶ã‚¤ãƒ³',
                'éç†±ä¿è­·ã‚·ã‚¹ãƒ†ãƒ æ­è¼‰',
                'ä¸¸æ´—ã„å¯èƒ½',
                'PowerARQãƒ–ãƒ©ãƒ³ãƒ‰'
            ]
        
        features = []
        points = sales_text.split('\\n')
        for point in points:
            if point.strip():
                # ã‚»ãƒ¼ãƒ«ã‚¹ãƒã‚¤ãƒ³ãƒˆã‚’ç‰¹å¾´ã«å¤‰æ›
                if 'æ¸©åº¦è¨­å®š' in point:
                    features.append('10æ®µéšã®æ¸©åº¦èª¿ç¯€æ©Ÿèƒ½')
                elif 'ã‚«ãƒ©ãƒ¼ãƒ‡ã‚¶ã‚¤ãƒ³' in point or 'ã‚¤ãƒ³ãƒ†ãƒªã‚¢' in point:
                    features.append('ã‚­ãƒ£ãƒ³ãƒ—ã‚®ã‚¢ã«åˆã†ãƒ‡ã‚¶ã‚¤ãƒ³')
                elif 'é›»ç†±ç·š' in point or 'æš–ã‹' in point:
                    features.append('ã‚ˆã‚Šæš–ã‹ã•ã‚’æ„Ÿã˜ã‚„ã™ã„ç´ ææ„Ÿ')
                elif 'éç†±ä¿è­·' in point:
                    features.append('éç†±ä¿è­·ã‚·ã‚¹ãƒ†ãƒ æ­è¼‰')
                elif 'ä¸¸æ´—ã„' in point:
                    features.append('ä¸¸æ´—ã„å¯èƒ½ã§ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ç°¡å˜')
        
        return features if features else [
            '10æ®µéšã®æ¸©åº¦èª¿ç¯€æ©Ÿèƒ½',
            'ã‚¢ã‚¦ãƒˆãƒ‰ã‚¢å‘ã‘ãƒ‡ã‚¶ã‚¤ãƒ³', 
            'éç†±ä¿è­·ã‚·ã‚¹ãƒ†ãƒ æ­è¼‰',
            'ä¸¸æ´—ã„å¯èƒ½'
        ]
    
    def _create_page_details(self, spec_data: Dict) -> List[Dict]:
        """ãƒšãƒ¼ã‚¸è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
        product_name = spec_data.get('å•†å“å', 'PowerArQ Electric Blanket Lite')
        
        page_details = [
            {
                'text': f'{product_name}\\n\\nã‚¢ã‚¦ãƒˆãƒ‰ã‚¢ã§ã‚‚æš–ã‹ã\\n\\nâ€¢ 10æ®µéšã®æ¸©åº¦èª¿ç¯€\\nâ€¢ ã‚­ãƒ£ãƒ³ãƒ—ã‚®ã‚¢ã«åˆã†ãƒ‡ã‚¶ã‚¤ãƒ³\\nâ€¢ ä¸¸æ´—ã„å¯èƒ½',
                'layout_note': 'ã‚¢ã‚¦ãƒˆãƒ‰ã‚¢ã‚·ãƒ¼ãƒ³ã§ã®å•†å“ä½¿ç”¨ã‚¤ãƒ¡ãƒ¼ã‚¸',
                'has_images': True
            },
            {
                'text': 'PowerARQãƒ–ãƒ©ãƒ³ãƒ‰Ã—ã‚¢ã‚¦ãƒˆãƒ‰ã‚¢\\n\\nä¿¡é ¼ã®ãƒ–ãƒ©ãƒ³ãƒ‰ãŒææ¡ˆã™ã‚‹\\næ–°ã—ã„ã‚¢ã‚¦ãƒˆãƒ‰ã‚¢ä½“é¨“',
                'layout_note': 'ãƒ–ãƒ©ãƒ³ãƒ‰ãƒ­ã‚´ã¨ã‚¢ã‚¦ãƒˆãƒ‰ã‚¢ã‚·ãƒ¼ãƒ³',
                'has_images': True
            },
            {
                'text': '10æ®µéšã®æ¸©åº¦èª¿ç¯€\\n\\nã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ã§ç°¡å˜æ“ä½œ\\n\\nä½“èª¿ã‚„æ°—å€™ã«åˆã‚ã›ã¦\\nãŠå¥½ã¿ã®æš–ã‹ã•ã«',
                'layout_note': 'ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ã®æ“ä½œã‚¤ãƒ¡ãƒ¼ã‚¸',
                'has_images': True
            },
            {
                'text': 'ã‚¢ã‚¦ãƒˆãƒ‰ã‚¢å¯¾å¿œç´ æ\\n\\nã‚ˆã‚Šæš–ã‹ã•ã‚’æ„Ÿã˜ã‚„ã™ã„\\né›»ç†±ç·šé…ç½®ã¨ãƒãƒªã‚¨ã‚¹ãƒ†ãƒ«ç´ æ',
                'layout_note': 'ç´ æã®è³ªæ„Ÿã¨é›»ç†±ç·šé…ç½®ã®èª¬æ˜',
                'has_images': True
            },
            {
                'text': 'ã‚­ãƒ£ãƒ³ãƒ—ã‹ã‚‰è‡ªå®…ã¾ã§\\n\\nãƒ†ãƒ³ãƒˆå†…ãƒ»è»Šä¸­æ³Šãƒ»ãƒªãƒ“ãƒ³ã‚°\\nã‚ã‚‰ã‚†ã‚‹ã‚·ãƒ¼ãƒ³ã§æ´»èº',
                'layout_note': 'æ§˜ã€…ãªä½¿ç”¨ã‚·ãƒ¼ãƒ³ã®å†™çœŸ',
                'has_images': True
            },
            {
                'text': f'ä»•æ§˜ãƒ»ã‚¹ãƒšãƒƒã‚¯\\n\\n{spec_data.get("å•†å“ã‚µã‚¤ã‚º(cm)", "ç´„188Ã—130cm")}\\n{spec_data.get("1å€‹ é‡é‡(kg)", "ç´„2.0kg")}\\n{spec_data.get("å®šæ ¼", "äº¤æµ100V / 115W")}',
                'layout_note': 'ã‚¹ãƒšãƒƒã‚¯è¡¨ã¨ã‚µã‚¤ã‚ºæ„Ÿã®æ¯”è¼ƒ',
                'has_images': True
            },
            {
                'text': 'ã‚«ãƒ©ãƒ¼ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³\\n\\nãƒ–ãƒ©ãƒƒã‚¯ãƒ»ãƒ™ãƒ¼ã‚¸ãƒ¥ã®2è‰²å±•é–‹\\nã‚­ãƒ£ãƒ³ãƒ—ã‚®ã‚¢ã«åˆã‚ã›ã¦ãŠé¸ã³ãã ã•ã„',
                'layout_note': '2è‰²ä¸¦ã¹ãŸã‚«ãƒ©ãƒ¼æ¯”è¼ƒ',
                'has_images': True
            },
            {
                'text': 'å®‰å…¨æ©Ÿèƒ½ãƒ»ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹\\n\\néç†±ä¿è­·ã‚·ã‚¹ãƒ†ãƒ æ­è¼‰\\nä¸¸æ´—ã„å¯èƒ½ã§æ¸…æ½”ã«ä½¿ç”¨',
                'layout_note': 'å®‰å…¨æ©Ÿèƒ½ã¨æ´—æ¿¯æ–¹æ³•ã®èª¬æ˜',
                'has_images': True
            },
            {
                'text': 'ã‚ˆãã‚ã‚‹è³ªå•\\n\\nQ: ã‚­ãƒ£ãƒ³ãƒ—ã§ä½¿ãˆã¾ã™ã‹ï¼Ÿ\\nA: ã¯ã„ã€ACé›»æºãŒã‚ã‚Œã°å±‹å¤–ã§ã‚‚ä½¿ç”¨å¯èƒ½ã§ã™',
                'layout_note': 'FAQå½¢å¼ã§è¦‹ã‚„ã™ã',
                'has_images': False
            },
            {
                'text': 'è²©å£²åº—æƒ…å ±\\n\\nå…¨å›½ã®ã‚¢ã‚¦ãƒˆãƒ‰ã‚¢ç”¨å“åº—\\nå®¶é›»é‡è²©åº—ã§è²©å£²äºˆå®š',
                'layout_note': 'è²©å£²åº—ãƒ­ã‚´ã¨è³¼å…¥æ–¹æ³•',
                'has_images': True
            }
        ]
        
        return page_details
    
    def generate_lp_from_kishima_csv(self, csv_path: str, upload_to_docbase: bool = False) -> Dict[str, Any]:
        """åŠ å³¶å•†äº‹è¦å®šæ›¸CSVã‹ã‚‰LPãƒ©ãƒ•æ¡ˆã‚’ç”Ÿæˆ"""
        print(f"\nğŸ“‹ è¦å®šæ›¸è§£æé–‹å§‹: {csv_path}")
        
        # CSVè§£æ
        try:
            product_data = self.parse_kishima_csv(csv_path)
            print(f"âœ… è¦å®šæ›¸è§£æå®Œäº†: {product_data['product_name']}")
        except Exception as e:
            print(f"âŒ è¦å®šæ›¸èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return None
        
        # LPãƒ©ãƒ•æ¡ˆç”Ÿæˆ
        lp_content = self.lp_generator.generate_lp_rough(product_data)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        product_name = product_data['product_name'].replace(' ', '_')
        output_filename = f"lp_rough_{product_name}_{timestamp}.md"
        output_path = os.path.join('output', output_filename)
        
        # outputãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
        os.makedirs('output', exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(lp_content)
        
        print(f"âœ… LPãƒ©ãƒ•æ¡ˆç”Ÿæˆå®Œäº†: {output_path}")
        
        result = {
            'lp_content': lp_content,
            'output_path': output_path,
            'product_data': product_data
        }
        
        # Docbaseã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        if upload_to_docbase:
            try:
                uploader = DocbaseLPUploader()
                title = f"ã€LPãƒ©ãƒ•æ¡ˆã€‘{product_data['product_name']}"
                tags = ['LPãƒ©ãƒ•æ¡ˆ', 'PowerArQ', 'é›»æ°—æ¯›å¸ƒ', 'è¦å®šæ›¸ç”Ÿæˆ', 'ã‚¢ã‚¦ãƒˆãƒ‰ã‚¢']
                
                print(f"\nğŸ“¤ Docbaseã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­...")
                docbase_result = uploader.create_lp_post(title, lp_content, tags)
                
                result['docbase_url'] = docbase_result['url']
                result['docbase_id'] = docbase_result['id']
                
                print(f"âœ… Docbaseã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†")
                print(f"ğŸ“ URL: {docbase_result['url']}")
                
            except Exception as e:
                print(f"âŒ Docbaseã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        
        return result

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  python kishima_spec_to_lp.py <è¦å®šæ›¸CSVãƒ•ã‚¡ã‚¤ãƒ«> [--upload]")
        print("\nä¾‹:")
        print("  python kishima_spec_to_lp.py /path/to/è¦å®šæ›¸ä¸€è¦§_åŠ å³¶å•†äº‹ - é›»æ°—æ¯›å¸ƒï¼ˆå»‰ä¾¡ç‰ˆï¼‰.csv")
        print("  python kishima_spec_to_lp.py /path/to/è¦å®šæ›¸ä¸€è¦§_åŠ å³¶å•†äº‹ - é›»æ°—æ¯›å¸ƒï¼ˆå»‰ä¾¡ç‰ˆï¼‰.csv --upload")
        sys.exit(1)
    
    csv_path = sys.argv[1]
    upload_flag = '--upload' in sys.argv
    
    if not os.path.exists(csv_path):
        print(f"âŒ è¦å®šæ›¸CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_path}")
        sys.exit(1)
    
    try:
        generator = KishimaSpecToLPGenerator()
        result = generator.generate_lp_from_kishima_csv(csv_path, upload_to_docbase=upload_flag)
        
        if result:
            print(f"\nğŸ‰ å‡¦ç†å®Œäº†ï¼")
            print(f"ğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {result['output_path']}")
            if 'docbase_url' in result:
                print(f"ğŸŒ Docbase URL: {result['docbase_url']}")
        else:
            print("âŒ å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ")
            sys.exit(1)
            
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()